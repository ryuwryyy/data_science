{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "import chainer\n",
    "import cv2\n",
    "import numpy as np\n",
    "import six\n",
    "from chainer import iterators\n",
    "from chainer import training\n",
    "from chainer.iterators import SerialIterator\n",
    "from chainer.optimizer import WeightDecay\n",
    "from chainer.training import extensions, updaters\n",
    "\n",
    "from modules.args_utils import BracesAction, ByteType, ColorType, DimensionType, PercentType, UnifiedType\n",
    "from modules.args_utils import DictParser, ObjectParser\n",
    "from modules.common import AUGMENTERS, OPTIMIZERS, setup_model\n",
    "from modules.image_dataset import CropExample, PatchAmplifier, RandomPatchAmplifier\n",
    "from modules.image_dataset import LabeledImageDataset\n",
    "from modules.image_dataset import MapColorOfExample, ResizeExample, SubtractFromExample, TransposeExample\n",
    "from modules.io_utils import print, progress_message\n",
    "\n",
    "\n",
    "def create_args():\n",
    "    n_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # train\n",
    "    parser.add_argument('--gpu', '-g', type=int, nargs='+',\n",
    "                        help='GPU IDs (negative value indicates CPU)')\n",
    "    parser.add_argument('--multiprocess', '-p', type=int, choices=six.moves.range(1, 256 + 1), nargs='?', const=n_cpus,\n",
    "                        help='Use multiprocess updater', metavar='1-256')\n",
    "    parser.add_argument('--epoch', type=int, required=True)\n",
    "    parser.add_argument('--batch_size', '-b', type=int, default=128,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--seed', type=int,\n",
    "                        help='Seed to do deterministic training. Keep in mind that this option decreases performance')\n",
    "    parser.add_argument('--cache', type=ByteType(), nargs='?', const=True)\n",
    "\n",
    "    # model\n",
    "    parser.add_argument('--model', required=True,\n",
    "                        choices=['mnih_cnn_multi', 'fcrn_v1', 'fcrn_v2', 'fcrn_v3', 'fcrn_v4', 'fcrn_v5', 'fcrn_v6'])\n",
    "    parser.add_argument('--nlabels', type=int, default=3)\n",
    "    parser.add_argument('--class_weight', type=float, nargs='*', metavar='float',\n",
    "                        help='Class weights')\n",
    "    parser.add_argument('--mapping', type=DictParser(ColorType(tuple), int),\n",
    "                        default={(0x00, 0x00, 0x80): 0, (0x00, 0x80, 0x00): 1, (0x80, 0x00, 0x00): 2},\n",
    "                        metavar='COLOR=LABEL,COLOR=LABEL,...')\n",
    "    parser.add_argument('--mapping_range', type=int, nargs=2, default=(0, 0))\n",
    "\n",
    "    # optimizers\n",
    "    parser.add_argument('--opt', type=ObjectParser(OPTIMIZERS), default=chainer.optimizers.MomentumSGD(),\n",
    "                        metavar='TYPE:PARAMS',\n",
    "                        help='type:value or type:name=value,name=value,...' +\n",
    "                             'Available optimizers: ' + ', '.join(six.iterkeys(OPTIMIZERS)))\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0005)\n",
    "\n",
    "    # dataset\n",
    "    parser.add_argument('--train', nargs='+', required=True,\n",
    "                        help='Csv files written image paths to train')\n",
    "    parser.add_argument('--valid', nargs='+', required=True,\n",
    "                        help='Csv files written image paths to validate')\n",
    "    parser.add_argument('--image_size', type=UnifiedType(DimensionType(), PercentType(min=1)),\n",
    "                        help='Size or scale to resize images')\n",
    "    parser.add_argument('--mean', '-m', nargs='?', const=True,\n",
    "                        help='Mean file (computed by compute_mean.py)')\n",
    "\n",
    "    # augmentation\n",
    "    parser.add_argument('--augment', type=ObjectParser(AUGMENTERS), nargs='+', action='append',\n",
    "                        metavar='TYPE:PARAMS',\n",
    "                        help='type:value or type:name=value,name=value,...' +\n",
    "                             'Available augmenters: ' + ', '.join(six.iterkeys(AUGMENTERS)))\n",
    "\n",
    "    # patch\n",
    "    parser.add_argument('--patch_size', type=int, nargs=2, default=None)\n",
    "    parser.add_argument('--patch_density', type=PercentType(min=1), default=1.)\n",
    "    parser.add_argument('--patch_ignore', type=ColorType(tuple))\n",
    "\n",
    "    # output\n",
    "    parser.add_argument('--out', '-o', default='out',\n",
    "                        help='Directory to output the training result')\n",
    "    parser.add_argument('--snapshot', type=int, default=1,\n",
    "                        help='Interval of saving models and snapshots')\n",
    "    parser.add_argument('--save_snapshot', action='store_true',\n",
    "                        help='Save snapshots for resume')\n",
    "    parser.add_argument('--resume', '-r',\n",
    "                        help='Snapshot to resume from')\n",
    "\n",
    "    # log\n",
    "    parser.add_argument('--class_labels', nargs='+', default=['blue', 'green', 'red'])\n",
    "    parser.add_argument('--display_entries', nargs='*', default=['accuracy'], action=BracesAction)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.class_weight and args.nlabels != len(args.class_weight):\n",
    "        raise Exception('nlabels and the number of class_weight is different')\n",
    "    if args.nlabels != len(args.class_labels):\n",
    "        raise Exception('nlabels and the number of class_labels is different')\n",
    "    if any(l >= args.nlabels for l in six.itervalues(args.mapping)):\n",
    "        raise Exception('Every mapped label must be less than nlabels')\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_optimizer(args, model):\n",
    "    optimizer = args.opt\n",
    "    optimizer.setup(model)\n",
    "    optimizer.add_hook(WeightDecay(args.weight_decay))\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def setup_dataset(args):\n",
    "    mapping = {color[::-1]: label for color, label in six.iteritems(args.mapping)}\n",
    "    mapper = MapColorOfExample(mapping, args.mapping_range)\n",
    "\n",
    "    train = LabeledImageDataset(args.train)\n",
    "    valid = LabeledImageDataset(args.valid)\n",
    "\n",
    "    # Resize images\n",
    "    if args.image_size:\n",
    "        size = args.image_size if isinstance(args.image_size, list) else None\n",
    "        scale = args.image_size if isinstance(args.image_size, float) else None\n",
    "        resize = ResizeExample(size, scale)\n",
    "        train = train.transform(resize)\n",
    "        valid = valid.transform(resize)\n",
    "\n",
    "    if args.cache:\n",
    "        # Cache resized images\n",
    "        if args.cache is True:\n",
    "            train = train.cache()\n",
    "            valid = valid.cache()\n",
    "        else:\n",
    "            total = len(train) + len(valid)\n",
    "            train = train.cache(len(train) * args.cache // total)\n",
    "            valid = valid.cache(len(valid) * args.cache // total)\n",
    "\n",
    "    # Compute and save mean\n",
    "    if args.mean:\n",
    "        if isinstance(args.mean, str):\n",
    "            mean = np.load(args.mean)\n",
    "            if args.image_size:\n",
    "                mean = resize.input(mean)\n",
    "        else:\n",
    "            n = len(train) + len(valid)\n",
    "            mean = 0\n",
    "            for image in itertools.chain(train.inputs, valid.inputs):\n",
    "                mean += image.astype(np.float32)\n",
    "            mean /= n\n",
    "\n",
    "            if not os.path.exists(args.out):\n",
    "                os.makedirs(args.out)\n",
    "            np.save(os.path.join(args.out, 'mean.npy'), mean)\n",
    "            cv2.imwrite(os.path.join(args.out, 'mean.png'), mean.astype(np.uint8))\n",
    "\n",
    "        train = train.transform(SubtractFromExample(mean))\n",
    "        valid = valid.transform(SubtractFromExample(mean))\n",
    "\n",
    "    if args.augment:\n",
    "        # Augment images\n",
    "        orig = train\n",
    "        for chain in args.augment:\n",
    "            train = train.chain(six.moves.reduce(lambda target, augmenter: target.amplify(augmenter), chain, orig))\n",
    "\n",
    "    # Make a patchwork\n",
    "    if args.patch_size:\n",
    "        input_size, label_size = args.patch_size\n",
    "\n",
    "        cropper = CropExample(None, (input_size - label_size) // 2)\n",
    "        kwargs = {\n",
    "            'image_ksize': (input_size, input_size),\n",
    "            'label_ksize': (label_size, label_size)\n",
    "        }\n",
    "\n",
    "        train = train.transform(cropper).amplify(RandomPatchAmplifier(density=args.patch_density, **kwargs))\n",
    "        valid = valid.transform(cropper).amplify(PatchAmplifier(**kwargs))\n",
    "\n",
    "        if args.patch_ignore:\n",
    "            bg = args.patch_ignore[::-1]\n",
    "\n",
    "            def is_fg(example):\n",
    "                image, label = example\n",
    "                return np.any(label != bg)\n",
    "\n",
    "            train = train.filter(is_fg)\n",
    "            valid = valid.filter(is_fg)\n",
    "\n",
    "    # Transpose images\n",
    "    train = train.transform(TransposeExample()).transform(mapper)\n",
    "    valid = valid.transform(TransposeExample()).transform(mapper)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        np.random.seed(args.seed)\n",
    "        if chainer.cuda.available:\n",
    "            chainer.cuda.cupy.seed(args.seed)\n",
    "\n",
    "        chainer.global_config.functions_deterministic = True\n",
    "        chainer.global_config.cudnn_deterministic = True\n",
    "\n",
    "    main_device = args.gpu[0] if args.gpu else -1\n",
    "\n",
    "    with progress_message('Loading dataset...'):\n",
    "        train, valid = setup_dataset(args)\n",
    "\n",
    "    if not train:\n",
    "        raise Exception('No training data')\n",
    "    if not valid:\n",
    "        raise Exception('No validation data')\n",
    "\n",
    "    with progress_message('Setting up model...'):\n",
    "        model = setup_model(args.model, main_device, args.nlabels, args.multiprocess, args.class_weight,\n",
    "                            args.class_labels)\n",
    "    optimizer = setup_optimizer(args, model)\n",
    "\n",
    "    n_processes = args.multiprocess if args.multiprocess else 1\n",
    "\n",
    "    train_iter = SerialIterator(train, args.batch_size)\n",
    "    valid_iter = SerialIterator(valid, args.batch_size, False, False)\n",
    "\n",
    "    if args.gpu and len(args.gpu) >= 2:\n",
    "        if len(args.gpu) != len(set(args.gpu)):\n",
    "            raise Exception('GPU specification must be unique')\n",
    "\n",
    "        devices = {'main': main_device}\n",
    "        devices.update(enumerate(args.gpu[1:], 1))\n",
    "\n",
    "        if n_processes >= 2:\n",
    "            train_iter = []\n",
    "            for i in chainer.datasets.split_dataset_n_random(train, len(devices)):\n",
    "                train_iter.append(iterators.MultiprocessIterator(i, args.batch_size, n_processes=n_processes))\n",
    "            valid_iter = iterators.MultiprocessIterator(valid, args.batch_size, False, False, n_processes=n_processes)\n",
    "\n",
    "            updater = updaters.MultiprocessParallelUpdater(train_iter, optimizer, devices=devices)\n",
    "        else:\n",
    "            updater = training.ParallelUpdater(train_iter, optimizer, devices=devices)\n",
    "    else:\n",
    "        updater = training.StandardUpdater(train_iter, optimizer, device=main_device)\n",
    "\n",
    "    trainer = training.Trainer(updater, (args.epoch, 'epoch'), out=args.out)\n",
    "\n",
    "    trainer.extend(extensions.dump_graph(root_name='main/loss'))\n",
    "\n",
    "    trainer.extend(extensions.Evaluator(valid_iter, model, device=main_device))\n",
    "\n",
    "    if args.save_snapshot:\n",
    "        trainer.extend(extensions.snapshot(), trigger=(args.snapshot, 'epoch'))\n",
    "    trainer.extend(extensions.snapshot_object(model, 'model_epoch_{.updater.epoch}'), trigger=(args.snapshot, 'epoch'))\n",
    "\n",
    "    trainer.extend(extensions.observe_lr())\n",
    "\n",
    "    trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "    trainer.extend(extensions.LogReport())\n",
    "\n",
    "    entries = [\n",
    "        'epoch', 'main/loss', 'validation/main/loss',\n",
    "    ]\n",
    "\n",
    "    for entry in args.display_entries:\n",
    "        entries += [\n",
    "            'main/{}'.format(entry),\n",
    "            'validation/main/{}'.format(entry)\n",
    "        ]\n",
    "\n",
    "    entries += ['lr', 'elapsed_time']\n",
    "\n",
    "    trainer.extend(extensions.PrintReport(entries))\n",
    "\n",
    "    trainer.extend(extensions.ProgressBar(update_interval=2))\n",
    "\n",
    "    if args.resume:\n",
    "        chainer.serializers.load_npz(args.resume, trainer)\n",
    "\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = create_args()\n",
    "    print(args)\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
